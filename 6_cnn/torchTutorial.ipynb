{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial\n",
    "\n",
    "기초 PyTorch 문법들을 정리해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 버전을 프린트해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=9, micro=10, releaselevel='final', serial=0)\n",
      "1.13.0.dev20220812\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version_info)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch는 엔비디아 GPU를 사용해 CUDA 가속을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA capable device found\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"No CUDA capable device found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Initialization\n",
    "\n",
    "먼저 PyTorch의 기본 자료형인 Tensor는 다음과 같이 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n",
      "[tensor(1), tensor(2), tensor(3)]\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# 리스트를 통해 텐서 만들기\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print(a)\n",
    "\n",
    "# numpy 배열을 통해 텐서 만들기\n",
    "a = torch.tensor(np.array([1, 2, 3]))\n",
    "print(a)\n",
    "\n",
    "# 텐서를 통해 리스트 만들기\n",
    "a = list(torch.tensor([1, 2, 3]))\n",
    "print(a)\n",
    "\n",
    "# 텐서를 통해 numpy 배열 만들기\n",
    "a = torch.tensor([1, 2, 3]).numpy()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```np.zeros```나 ```np.ones```와 유사하게 사용할 수도 있습니다. NumPy에서 가능했던 변환들이 Tensor에서도 대부분 비슷하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1., 2., 3.])\n",
      "tensor(1)\n",
      "tensor([10,  2,  3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 0으로 초기화된 텐서 만들기\n",
    "a = torch.zeros(3, 3)\n",
    "print(a)\n",
    "\n",
    "# 1으로 초기화된 텐서 만들기\n",
    "a = torch.ones(3, 3)\n",
    "print(a)\n",
    "\n",
    "# 정수형 텐서 만들기\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.int64)\n",
    "print(a)\n",
    "\n",
    "# 실수형 텐서 만들기\n",
    "a = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "print(a)\n",
    "\n",
    "# 텐서의 요소를 각각 출력하기\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print(a[0])\n",
    "\n",
    "# 텐서 내에서 요소를 수정하기\n",
    "a[0] = 10\n",
    "print(a)\n",
    "\n",
    "# 텐서의 크기 확인하기\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈을 사용하여 텐서 만들기\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, 3)\n",
    "        self.conv2 = nn.Conv2d(1, 1, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "torch.Size([1, 1, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "# 모듈을 사용하여 텐서 만들기\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# 텐서를 사용하여 모듈을 사용하기\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "out = net(x)\n",
    "print(out.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조금 더 복잡한 모듈 만들기\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.query = nn.Linear(feature_dim, feature_dim, bias)\n",
    "        self.key = nn.Linear(feature_dim, feature_dim, bias)\n",
    "        self.value = nn.Linear(feature_dim, feature_dim, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        step = x.shape[-2]\n",
    "        feature = x.shape[-1]\n",
    "\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "\n",
    "        query = query.view(step, -1, feature)\n",
    "        key = key.view(step, -1, feature)\n",
    "        value = value.view(step, -1, feature)\n",
    "\n",
    "        attention = torch.bmm(query, key.transpose(1, 2))\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "        attention = torch.bmm(attention, value)\n",
    "        attention = attention.view(step, -1, feature)\n",
    "\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention(\n",
      "  (query): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (key): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (value): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 조금 더 복잡한 모듈 사용하기\n",
    "net = Attention(1, 1)\n",
    "print(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Acceleration\n",
    "\n",
    "PyTorch는 GPU 가속을 지원합니다. GPU 가속을 하기 위해서는 가속할 연산에 사용할 텐서들을 VRAM으로 옮겨 연산해야 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEVICE를 설정합니다. DEVICE는 보통 'cpu', 'cuda' 2가지가 있습니다.\n",
    "\n",
    "만약 여러 개의 GPU를 활용한다면 DEVICE 뒤에 인덱스가 붙습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device 설정하기\n",
    "DEVICE = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "별 언급이 없으면 디폴트로는 CPU memory에 텐서가 저장됩니다. ```to``` 메소드를 통해 정의된 텐서의 위치를 옮겨줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], device='mps:0')\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# 텐서를 설정한 device로 만들기\n",
    "a = torch.tensor([1, 2, 3], device=DEVICE)\n",
    "print(a)\n",
    "print(a.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# CPU에서 텐서 생성하기\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print(a.device)\n",
    "a = a.to(\"cpu\")\n",
    "print(a.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# GPU에서 텐서 생성하기\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print(a.device)\n",
    "a = a.to(DEVICE)\n",
    "print(a.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Performance 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9628162920000012\n"
     ]
    }
   ],
   "source": [
    "# CPU 시간 측정하기\n",
    "a = torch.ones(1000, 1000)\n",
    "b = torch.ones(1000, 100)\n",
    "start = time.perf_counter()\n",
    "for _ in range(10000):\n",
    "    (a@b).mean().item()\n",
    "print(time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.180795041000001\n"
     ]
    }
   ],
   "source": [
    "# GPU 시간 측정하기\n",
    "a = torch.ones(1000, 1000, device=DEVICE)\n",
    "b = torch.ones(1000, 100, device=DEVICE)\n",
    "start = time.perf_counter()\n",
    "for _ in range(10000):\n",
    "    (a@b).mean().item()\n",
    "print(time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈을 이용해서 텐서 생성하기\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      ")\n",
      "0.5003753329999974\n"
     ]
    }
   ],
   "source": [
    "# CPU에서 텐서 생성하기\n",
    "module = Net()\n",
    "print(module)\n",
    "\n",
    "x = torch.zeros(100, 100)\n",
    "start = time.perf_counter()\n",
    "for _ in range(10000):\n",
    "    module(x).mean().item()\n",
    "print(time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      ")\n",
      "5.791816541999999\n"
     ]
    }
   ],
   "source": [
    "# GPU 에서 텐서 생성하기\n",
    "module = Net().to(DEVICE)\n",
    "print(module)\n",
    "\n",
    "x = torch.zeros(100, 100, device=DEVICE)\n",
    "start = time.perf_counter()\n",
    "for _ in range(10000):\n",
    "    module(x).mean().item()\n",
    "print(time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efaaffe9068f6e7dc4e7db139e9a8ff91e5a2b37fb0a8de094ded86cab042f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
